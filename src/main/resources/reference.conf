lucenerdd {

  // Name of analyzer as it is under Lucene's package org.apache.lucene.analysis.XX
  analyzer.name = "en"

  // Analyzer name must be "ngram"
  analyzer {
    ngram.mingram = 2
    ngram.maxgram = 5
  }

  // Similarity scoring for Lucenes
  similarity.name = "bm25" // anything else will default to Lucene classic similarity

  // Supported linkage methods
  // "collectbroadcast" : Collects the RDD that contains the queries (to be used only if query RDD
  // fits in spark driver's memory)
  //
  // "cartesian" : Uses cartesian product between the partitions of the queries RDD and the partitions
  // of LuceneRDD. Note it duplicates each partition of LuceneRDD n times where n is the number of
  // partitions of the queries RDD.
  linker.method = "collectbroadcast"

  index {

    // Lucene index storage
    // Use 'disk' to store the index in Java's temp directory
    // Otherwise the index will be stored in memory
    // Do not use memory, see http://lucene.apache.org/core/7_5_0/core/org/apache/lucene/store/RAMDirectory.html
    store.mode = "disk"

    stringfields{

      // Analyze string fields by default or not
      // Implicit fields, like _1, _2, etc will use this option
      analyzed = true

      // Select a subset of string fields that you do not wish to be analyzed
      // Due to serialization issues this list should be set before starting a Spark Session
      // Moreover, all text/string fields that end with '_notanalyzed' are not analyzed
      not_analyzed_list = []

      // Text fields options as in org.apache.lucene.index.IndexOptions
      //
      // Other options are:
      // "DOCS"
      // "DOCS_AND_FREQS"
      // "DOCS_AND_FREQS_AND_POSITIONS"
      // "DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS"
      // "NONE"
      options = "docs_and_freqs_and_positions_and_offsets"

      // Omit terms norms
      terms.omitnorms = false

      // Store term positions
      terms.positions = false

      // Store Term vectors (set true, otherwise LuceneRDD.termVectors(fieldName) will fail)
      terms.vectors = true
    }
  }

  // Maximum value on topK queries
  query.topk.maxvalue = 100
  // Default value of number of returned results
  query.topk.default = 10

  // Default value of number of faceted results
  query.facets.number.default = 10

  // Spatial related configurations used by ShapeLuceneRDD
  spatial {
    prefixtree {
      name = "quad"  // "geohash" or "quad"
      maxlevel = 9 // 11 results in sub-meter precision for geohash
      maxDistErr = 5.0 // in kilometers
    }

    // Shape format can be one of ShapeIO.GeoJSON, ShapeIO.LEGACY, ShapeIO.POLY, ShapeIO.WKT
    shape.io.format = "WKT"

    // Supported linkage methods
    // "collectbroadcast" : Collects the RDD that contains the queries (to be used only if query RDD
    // fits in spark driver's memory)
    //
    // "cartesian" : Uses cartesian product between the partitions of the queries RDD and the partitions
    // of LuceneRDD. Note it duplicates each partition of LuceneRDD n times where n is the number of
    // partitions of the queries RDD.
    linker.method = "collectbroadcast"
  }
}
